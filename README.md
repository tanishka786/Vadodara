# Echo Assist: Comprehensive Multi-Modal Communication Tools

---

## Overview
**Echo Assist** is a collection of innovative tools designed to break communication barriers using cutting-edge technologies. These tools facilitate interaction between users with diverse communication needs, ensuring accessibility and inclusivity.

Our project includes:
1. **Real-time Sign Language Translation Tool**
2. **Sign-Language-Translator**
3. **Vision Keyboard: A Blink-Controlled Virtual Keyboard**

---

## Tools Overview

### 1. Real-Time Sign Language Translation Tool

**Purpose**: To provide seamless translation between sign language and text/audio for enhanced accessibility and communication.

**Key Features**:
- **Real-time Speech Recognition**: Converts spoken language into text.
- **Instant Translation**: Real-time translation into the target language.
- **Speech Synthesis**: Converts translated text into natural-sounding speech.
- **Multi-language Support**: Supports a wide range of languages.
- **User-Friendly Interface**: Intuitive and accessible for diverse users.

**Tech Stack**:
- **Front-End**: HTML5, CSS3, JavaScript
- **Back-End**: Node.js, Express.js
- **APIs**: Google Speech-to-Text, Google Translate, Google Text-to-Speech

**How to Run**:
```bash
# Clone the repository
git clone https://github.com/yourusername/echo-assist.git

# Navigate to the directory
cd echo-assist

# Install dependencies
npm install

# Start the server
npm start

# Access the tool in your browser
http://localhost:3000
```

---

### 2. Sign-Language-Translator

**Purpose**: Real-time translation of sign language into text/speech, enabling effective communication with gestures.

**Key Features**:
- **Hand Gesture Training and Classification**: Train and classify hand gestures dynamically.
- **Light Condition Adaptability**: Works effectively in varying lighting conditions.
- **Video Call Functionality**: Communicate using gestures over video calls.
- **Minimal Memory Usage**: Efficient performance for real-time use.
- **Text-to-Speech**: Converts translated gestures into speech.
- **Clipboard Copying**: Copy translated text for further use.

**Tech Stack**:
- **Front-End & Back-End**: JavaScript, TensorFlow

**Deployment**: [Sign-Language-Translator](https://sllllt.netlify.app/)

**How to Run**:
```bash
# Clone the repository
git clone https://github.com/yourusername/sign-language-translator.git

# Navigate to the directory
cd sign-language-translator

# Install dependencies
npm install

# Build the project
npm run build

# Start the application
npm start

# Access the tool in your browser
http://localhost:9966
```

---

### 3. Vision Keyboard: A Blink-Controlled Virtual Keyboard

**Purpose**: Enables users to type using eye blinks, leveraging computer vision and facial landmark detection.

**Key Features**:
- **Real-Time Blink Detection**: Detects eye blinks for interaction.
- **Virtual Keyboard**: Allows text input without traditional hardware.
- **Customizable Keys**: Configure the keyboard layout and functionality.
- **Low Resource Usage**: Runs efficiently on standard hardware.

**Tech Stack**:
- **Libraries**: OpenCV, NumPy, dlib
- **Programming Language**: Python

**Deployment**: [Vision Keyboard](https://simuuuu.netlify.app/)

**How to Run**:
```bash
# Clone the repository
git clone https://github.com/yourusername/vision-keyboard.git

# Navigate to the directory
cd vision-keyboard

# Install dependencies
pip install opencv-python numpy dlib

# Run the application
python vision_keyboard.py

# Use the tool
Follow on-screen instructions to interact with the virtual keyboard.
```

---

## Contribution
This project is open-source and welcomes contributions! Feel free to fork, modify, and submit pull requests.

For queries, contact:
- **Pulkit Ashara**: pulkit.221143101@vcet.edu.in
- **Mayur Bhamare**: mayur.221243102@vcet.edu.in
- **Shailesh Agrawal**: shailesh.221123109@vcet.edu.in

Mentor: **Dr. Megha Trivedi**

---

## Visual Overview

### Workflow
1. **Sign Language Translation Tool**: Recognizes, translates, and synthesizes sign language in real-time.
2. **Sign-Language-Translator**: Converts gestures into text/speech, enabling gesture-based communication.
3. **Vision Keyboard**: Facilitates typing with eye blinks, ensuring accessibility for users with limited mobility.


## Acknowledgments
Special thanks to **Team Deciphers** for their hard work and innovation in creating Echo Assist.

